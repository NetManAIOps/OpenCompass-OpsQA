,Fluency,Accuracy,Evidence,Total
baichuan-13b-chat,2.4,1.12,1.02,4.54
chinese-alpaca-2-13b,2.9,1.52,1.82,6.24
GPT-3.5-turbo,3.0,1.96,1.2,6.16
llama-2-13b-chat,2.82,1.34,1.62,5.78
qwen_chat_7b,2.56,1.14,0.84,4.54
chatglm2-6b,2.84,0.76,0.76,4.36
chinese-llama-2-13b,1.42,0.72,0.18,2.32
internlm_chat_7b,1.8,0.7,0.1,2.6
llama-2-70b-int4,2.92,1.48,1.32,5.72
llama-2-7b-chat,0.0,0.0,0.0,0.0
